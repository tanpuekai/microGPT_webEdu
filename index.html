<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MicroGPT - Educational Visualization</title>
    <style>
        :root {
            --bg-primary: #0f172a;
            --bg-secondary: #1e293b;
            --bg-tertiary: #334155;
            --text-primary: #f1f5f9;
            --text-secondary: #94a3b8;
            --accent-blue: #3b82f6;
            --accent-purple: #8b5cf6;
            --accent-green: #10b981;
            --accent-orange: #f97316;
            --accent-red: #ef4444;
            --accent-yellow: #eab308;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.6;
        }

        header {
            background: linear-gradient(135deg, var(--bg-secondary) 0%, var(--bg-tertiary) 100%);
            padding: 2rem;
            border-bottom: 2px solid var(--accent-blue);
        }

        header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, var(--accent-blue), var(--accent-purple));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        header p {
            color: var(--text-secondary);
            font-size: 1.1rem;
        }

        .paper-link {
            display: inline-block;
            margin-top: 1rem;
            padding: 0.5rem 1rem;
            background: var(--accent-blue);
            color: white;
            text-decoration: none;
            border-radius: 8px;
            font-size: 0.9rem;
            transition: all 0.3s ease;
        }

        .paper-link:hover {
            background: var(--accent-purple);
            transform: translateY(-2px);
        }

        main {
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
        }

        .section {
            background: var(--bg-secondary);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
        }

        .section h2 {
            color: var(--accent-blue);
            margin-bottom: 1.5rem;
            font-size: 1.8rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .section h3 {
            color: var(--accent-purple);
            margin: 1.5rem 0 1rem;
            font-size: 1.3rem;
        }

        .section p {
            color: var(--text-secondary);
            margin-bottom: 1rem;
        }

        .code-snippet {
            background: var(--bg-primary);
            border-radius: 8px;
            padding: 1rem;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.85rem;
            overflow-x: auto;
            border-left: 3px solid var(--accent-green);
            margin: 1rem 0;
        }

        .code-var {
            color: var(--accent-blue);
        }

        .code-func {
            color: var(--accent-purple);
        }

        .code-comment {
            color: var(--text-secondary);
            font-style: italic;
        }

        /* Architecture Diagram */
        .arch-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1rem;
            padding: 1rem;
        }

        .arch-block {
            background: var(--bg-tertiary);
            border: 2px solid var(--accent-blue);
            border-radius: 12px;
            padding: 1rem 1.5rem;
            min-width: 300px;
            text-align: center;
            position: relative;
            transition: all 0.3s ease;
        }

        .arch-block:hover {
            border-color: var(--accent-purple);
            transform: scale(1.05);
        }

        .arch-block.active {
            background: linear-gradient(135deg, var(--accent-blue), var(--accent-purple));
            border-color: var(--accent-green);
        }

        .arch-block .block-name {
            font-weight: bold;
            font-size: 1.1rem;
        }

        .arch-block .block-var {
            color: var(--accent-yellow);
            font-family: monospace;
            font-size: 0.9rem;
        }

        .arch-arrow {
            font-size: 2rem;
            color: var(--accent-blue);
        }

        .arch-row {
            display: flex;
            gap: 1rem;
            align-items: center;
        }

        /* Parameter Grid */
        .param-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
        }

        .param-card {
            background: var(--bg-primary);
            border: 1px solid var(--accent-blue);
            border-radius: 12px;
            padding: 1rem;
            text-align: center;
            transition: all 0.3s ease;
        }

        .param-card:hover {
            border-color: var(--accent-purple);
            transform: translateY(-3px);
            box-shadow: 0 4px 15px rgba(139, 92, 246, 0.3);
        }

        .param-card .param-name {
            color: var(--accent-green);
            font-family: monospace;
            font-size: 1.1rem;
            margin-bottom: 0.5rem;
        }

        .param-card .param-value {
            color: var(--accent-orange);
            font-size: 1.5rem;
            font-weight: bold;
        }

        /* Autograd Visualization */
        .graph-container {
            position: relative;
            height: 400px;
            background: var(--bg-primary);
            border-radius: 12px;
            overflow: hidden;
            border: 1px solid var(--accent-blue);
        }

        .graph-node {
            position: absolute;
            width: 80px;
            height: 80px;
            background: var(--bg-tertiary);
            border: 2px solid var(--accent-blue);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-family: monospace;
            font-size: 0.8rem;
            cursor: pointer;
            transition: all 0.3s ease;
            z-index: 2;
        }

        .graph-node:hover {
            background: var(--accent-blue);
            border-color: var(--accent-purple);
            transform: scale(1.1);
        }

        .graph-node.loss {
            border-color: var(--accent-red);
            background: rgba(239, 68, 68, 0.2);
        }

        .graph-node.param {
            border-color: var(--accent-green);
            border-radius: 8px;
        }

        .graph-node.active {
            box-shadow: 0 0 20px var(--accent-purple);
        }

        .graph-edge {
            position: absolute;
            height: 2px;
            background: var(--accent-blue);
            transform-origin: left center;
            z-index: 1;
            opacity: 0.5;
        }

        .gradient-display {
            background: var(--bg-primary);
            padding: 1rem;
            border-radius: 8px;
            margin-top: 1rem;
            font-family: monospace;
            border-left: 3px solid var(--accent-yellow);
        }

        /* Attention Mechanism */
        .attention-grid {
            display: grid;
            grid-template-columns: repeat(8, 1fr);
            gap: 2px;
            max-width: 400px;
            margin: 1rem auto;
        }

        .attention-cell {
            aspect-ratio: 1;
            background: var(--bg-tertiary);
            border-radius: 4px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.7rem;
            font-family: monospace;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .attention-cell:hover {
            transform: scale(1.2);
            z-index: 10;
        }

        .head-viz {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 1rem;
            margin-top: 1rem;
        }

        .head-card {
            background: var(--bg-primary);
            border: 1px solid var(--accent-blue);
            border-radius: 12px;
            padding: 1rem;
            text-align: center;
        }

        .head-card h4 {
            color: var(--accent-purple);
            margin-bottom: 0.5rem;
            font-family: monospace;
        }

        /* Training Flow */
        .flow-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .flow-step {
            display: flex;
            align-items: center;
            gap: 1rem;
            padding: 1rem;
            background: var(--bg-primary);
            border-radius: 12px;
            border-left: 4px solid var(--accent-blue);
            transition: all 0.3s ease;
        }

        .flow-step:hover {
            border-left-color: var(--accent-purple);
            background: var(--bg-tertiary);
        }

        .flow-step.active {
            border-left-color: var(--accent-green);
            background: linear-gradient(90deg, rgba(16, 185, 129, 0.1), transparent);
        }

        .flow-step-number {
            width: 40px;
            height: 40px;
            background: var(--accent-blue);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
        }

        .flow-step-content {
            flex: 1;
        }

        .flow-step-title {
            color: var(--text-primary);
            font-weight: bold;
            margin-bottom: 0.25rem;
        }

        .flow-step-desc {
            color: var(--text-secondary);
            font-size: 0.9rem;
        }

        /* Controls */
        .controls {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
            flex-wrap: wrap;
        }

        .btn {
            padding: 0.75rem 1.5rem;
            background: var(--accent-blue);
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1rem;
            transition: all 0.3s ease;
        }

        .btn:hover {
            background: var(--accent-purple);
            transform: translateY(-2px);
        }

        .btn.secondary {
            background: var(--bg-tertiary);
            border: 1px solid var(--accent-blue);
        }

        .btn.secondary:hover {
            background: var(--accent-blue);
        }

        /* Progress Bar */
        .progress-container {
            background: var(--bg-primary);
            border-radius: 8px;
            height: 30px;
            overflow: hidden;
            margin-top: 1rem;
        }

        .progress-bar {
            height: 100%;
            background: linear-gradient(90deg, var(--accent-blue), var(--accent-purple));
            transition: width 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.8rem;
        }

        /* Tabs */
        .tabs {
            display: flex;
            gap: 0.5rem;
            margin-bottom: 1rem;
            border-bottom: 2px solid var(--accent-blue);
        }

        .tab {
            padding: 0.75rem 1.5rem;
            background: transparent;
            color: var(--text-secondary);
            border: none;
            cursor: pointer;
            font-size: 1rem;
            transition: all 0.3s ease;
        }

        .tab:hover {
            color: var(--text-primary);
        }

        .tab.active {
            color: var(--accent-blue);
            border-bottom: 3px solid var(--accent-blue);
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        /* Tooltip */
        .tooltip {
            position: fixed;
            background: var(--bg-tertiary);
            border: 1px solid var(--accent-blue);
            border-radius: 8px;
            padding: 0.75rem;
            font-size: 0.85rem;
            max-width: 300px;
            z-index: 1000;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        .tooltip.show {
            opacity: 1;
        }

        /* Equations */
        .equation {
            background: var(--bg-primary);
            padding: 1rem;
            border-radius: 8px;
            text-align: center;
            font-family: 'Times New Roman', serif;
            font-style: italic;
            font-size: 1.1rem;
            margin: 1rem 0;
            border-left: 3px solid var(--accent-purple);
        }

        /* Layer Visualization */
        .layer-viz {
            display: flex;
            flex-direction: column;
            gap: 0.5rem;
        }

        .layer-item {
            display: flex;
            align-items: center;
            gap: 1rem;
            padding: 0.75rem;
            background: var(--bg-primary);
            border-radius: 8px;
            font-family: monospace;
            font-size: 0.9rem;
        }

        .layer-item .layer-label {
            color: var(--accent-purple);
            min-width: 150px;
        }

        .layer-item .layer-shape {
            color: var(--accent-orange);
        }

        /* Footer */
        footer {
            text-align: center;
            padding: 2rem;
            color: var(--text-secondary);
            border-top: 1px solid var(--bg-tertiary);
        }

        footer a {
            color: var(--accent-blue);
        }

        /* Responsive */
        @media (max-width: 768px) {
            header h1 {
                font-size: 1.8rem;
            }

            .arch-row {
                flex-direction: column;
            }

            .param-grid {
                grid-template-columns: repeat(2, 1fr);
            }
        }

        /* Animation for active elements */
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .pulse {
            animation: pulse 1s ease-in-out infinite;
        }

        /* Gradient text */
        .gradient-text {
            background: linear-gradient(135deg, var(--accent-blue), var(--accent-purple), var(--accent-green));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
    </style>
</head>
<body>
    <header>
        <h1>üß† MicroGPT Visualization</h1>
        <p>An interactive educational guide through a minimal GPT implementation in pure Python</p>
        <a href="https://arxiv.org/abs/1706.03762" target="_blank" class="paper-link">
            üìÑ Attention Is All You Need (2017)
        </a>
    </header>

    <main>
        <!-- Overview Section -->
        <section class="section">
            <h2>üìñ Overview</h2>
            <p>This visualization walks through <a href="microgpt.py" style="color:var(--accent-blue)">microgpt.py</a> - a complete GPT implementation in pure Python with zero external dependencies. It demonstrates the core Transformer architecture from the 2017 paper <a href="https://arxiv.org/abs/1706.03762" target="_blank" style="color:var(--accent-blue)">"Attention Is All You Need"</a>.</p>

            <div class="code-snippet">
<span class="code-comment"># The complete algorithm, nothing but efficiency elsewhere</span>
<span class="code-var">n_embd</span> = 16      <span class="code-comment"># embedding dimension</span>
<span class="code-var">n_head</span> = 4       <span class="code-comment"># number of attention heads</span>
<span class="code-var">n_layer</span> = 1      <span class="code-comment"># number of transformer layers</span>
<span class="code-var">block_size</span> = 8   <span class="code-comment"># maximum sequence length</span>
            </div>

            <div class="tabs">
                <button class="tab active" data-tab="architecture">Architecture</button>
                <button class="tab" data-tab="autograd">Autograd</button>
                <button class="tab" data-tab="attention">Attention</button>
                <button class="tab" data-tab="training">Training Loop</button>
            </div>

            <!-- Architecture Tab -->
            <div id="architecture" class="tab-content active">
                <h3>üèóÔ∏è Model Architecture</h3>
                <p>Flow from <span class="code-var">gpt(token_id, pos_id, keys, values)</span> function:</p>

                <div class="arch-container">
                    <div class="arch-row">
                        <div class="arch-block" data-block="input">
                            <div class="block-name">Input</div>
                            <div class="block-var">token_id, pos_id</div>
                        </div>
                        <div class="arch-arrow">‚Üí</div>
                        <div class="arch-block" data-block="embed">
                            <div class="block-name">Embeddings</div>
                            <div class="block-var">wte, wpe</div>
                        </div>
                    </div>

                    <div class="arch-arrow">‚Üì</div>

                    <div class="arch-block" data-block="prenorm">
                        <div class="block-name">Pre-Norm</div>
                        <div class="block-var">rmsnorm(x)</div>
                    </div>

                    <div class="arch-arrow">‚Üì</div>

                    <div class="arch-row">
                        <div class="arch-block" data-block="attn">
                            <div class="block-name">Multi-Head Attention</div>
                            <div class="block-var">attn_wq, attn_wk, attn_wv, attn_wo</div>
                        </div>
                        <div class="arch-arrow">+</div>
                        <div class="arch-block" data-block="residual1">
                            <div class="block-name">Residual</div>
                            <div class="block-var">x + x_attn</div>
                        </div>
                    </div>

                    <div class="arch-arrow">‚Üì</div>

                    <div class="arch-row">
                        <div class="arch-block" data-block="mlp">
                            <div class="block-name">MLP</div>
                            <div class="block-var">mlp_fc1, ReLU^2, mlp_fc2</div>
                        </div>
                        <div class="arch-arrow">+</div>
                        <div class="arch-block" data-block="residual2">
                            <div class="block-name">Residual</div>
                            <div class="block-var">x + x_mlp</div>
                        </div>
                    </div>

                    <div class="arch-arrow">‚Üì</div>

                    <div class="arch-block" data-block="output">
                        <div class="block-name">Output</div>
                        <div class="block-var">logits = lm_head(x)</div>
                    </div>
                </div>

                <h3>üìä Parameter Dimensions</h3>
                <div class="layer-viz">
                    <div class="layer-item">
                        <span class="layer-label">wte</span>
                        <span class="layer-shape">(vocab_size, n_embd)</span>
                        <span style="color:var(--text-secondary)">= (27, 16)</span>
                    </div>
                    <div class="layer-item">
                        <span class="layer-label">wpe</span>
                        <span class="layer-shape">(block_size, n_embd)</span>
                        <span style="color:var(--text-secondary)">= (8, 16)</span>
                    </div>
                    <div class="layer-item">
                        <span class="layer-label">attn_wq, attn_wk, attn_wv</span>
                        <span class="layer-shape">(n_embd, n_embd)</span>
                        <span style="color:var(--text-secondary)">= (16, 16)</span>
                    </div>
                    <div class="layer-item">
                        <span class="layer-label">attn_wo</span>
                        <span class="layer-shape">(n_embd, n_embd)</span>
                        <span style="color:var(--text-secondary)">= (16, 16)</span>
                    </div>
                    <div class="layer-item">
                        <span class="layer-label">mlp_fc1</span>
                        <span class="layer-shape">(4 * n_embd, n_embd)</span>
                        <span style="color:var(--text-secondary)">= (64, 16)</span>
                    </div>
                    <div class="layer-item">
                        <span class="layer-label">mlp_fc2</span>
                        <span class="layer-shape">(n_embd, 4 * n_embd)</span>
                        <span style="color:var(--text-secondary)">= (16, 64)</span>
                    </div>
                    <div class="layer-item">
                        <span class="layer-label">lm_head</span>
                        <span class="layer-shape">(vocab_size, n_embd)</span>
                        <span style="color:var(--text-secondary)">= (27, 16)</span>
                    </div>
                </div>

                <h3>üéÆ Interactive Architecture Controls</h3>
                <div class="controls">
                    <button class="btn" onclick="animateArchitecture()">‚ñ∂Ô∏è Animate Forward Pass</button>
                    <button class="btn secondary" onclick="resetArchitecture()">‚Ü∫ Reset</button>
                </div>
            </div>

            <!-- Autograd Tab -->
            <div id="autograd" class="tab-content">
                <h3>üîÑ The Value Class - Autograd Engine</h3>
                <p>The <span class="code-func">Value</span> class implements automatic differentiation by building a computation graph and applying the chain rule.</p>

                <div class="code-snippet">
class <span class="code-func">Value</span>:
    def <span class="code-func">__init__</span>(self, data, children=(), local_grads=()):
        self.data = data                <span class="code-comment"># forward pass value</span>
        self.grad = 0                   <span class="code-comment"># gradient (‚àÇloss/‚àÇnode)</span>
        self._children = children       <span class="code-comment"># graph edges</span>
        self._local_grads = local_grads <span class="code-comment"># ‚àÇself/‚àÇchild</span>
                </div>

                <h3>üìà Computation Graph Visualization</h3>
                <p>Click on a node to see its gradient information. The graph shows a simplified forward pass for a single output token.</p>

                <div class="graph-container" id="computationGraph">
                    <!-- Nodes will be generated by JavaScript -->
                </div>

                <div class="gradient-display" id="gradientInfo">
                    Hover over or click a node to see gradient information...
                </div>

                <h3>üîó Chain Rule in Action</h3>
                <div class="equation">
                    ‚àÇL/‚àÇx = Œ£<sub>y‚ààchildren(x)</sub> (‚àÇL/‚àÇy) √ó (‚àÇy/‚àÇx)
                </div>
                <p>The <span class="code-func">backward()</span> method topologically sorts the graph and propagates gradients from loss to all parameters.</p>

                <div class="code-snippet">
def <span class="code-func">backward</span>(self):
    <span class="code-comment"># Topological sort + gradient accumulation</span>
    self.grad = 1  <span class="code-comment"># ‚àÇloss/‚àÇloss = 1</span>
    for v in reversed(topo):
        for child, local_grad in zip(v._children, v._local_grads):
            child.grad += local_grad * v.grad
                </div>

                <h3>üéÆ Controls</h3>
                <div class="controls">
                    <button class="btn" onclick="animateBackprop()">‚ñ∂Ô∏è Animate Backpropagation</button>
                    <button class="btn secondary" onclick="resetGraph()">‚Ü∫ Reset</button>
                </div>
            </div>

            <!-- Attention Tab -->
            <div id="attention" class="tab-content">
                <h3>üëÅÔ∏è Multi-Head Attention Mechanism</h3>
                <p>Core innovation from "Attention Is All You Need" (2017). Each position attends to all previous positions with learnable weights.</p>

                <div class="code-snippet">
<span class="code-comment"># For each head h in range(n_head):</span>
q = <span class="code-func">linear</span>(x, attn_wq)  <span class="code-comment"># Query</span>
k = <span class="code-func">linear</span>(x, attn_wk)  <span class="code-comment"># Key</span>
v = <span class="code-func">linear</span>(x, attn_wv)  <span class="code-comment"># Value</span>

<span class="code-comment"># Scaled dot-product attention</span>
attn_logits = <span class="code-func">sum</span>(q * k) / head_dim**0.5
attn_weights = <span class="code-func">softmax</span>(attn_logits)
head_out = <span class="code-func">sum</span>(attn_weights * v)
                </div>

                <h3>üéØ Attention Pattern Visualization</h3>
                <p>Casual attention: each position can only attend to itself and previous positions. The heatmap shows attention weights (lighter = higher weight).</p>

                <div class="attention-grid" id="attentionGrid">
                    <!-- Generated by JavaScript -->
                </div>

                <div style="text-align: center; margin-top: 1rem; color: var(--text-secondary);">
                    Rows = Query positions (t), Columns = Key positions (œÑ)
                </div>

                <h3>üß© Multi-Head Structure</h3>
                <div class="head-viz">
                    <div class="head-card">
                        <h4>Head 0</h4>
                        <div style="font-size: 0.8rem; color: var(--text-secondary);">dim: 0-3</div>
                        <div style="margin-top: 0.5rem; color: var(--accent-green);">Q‚ÇÄ, K‚ÇÄ, V‚ÇÄ</div>
                    </div>
                    <div class="head-card">
                        <h4>Head 1</h4>
                        <div style="font-size: 0.8rem; color: var(--text-secondary);">dim: 4-7</div>
                        <div style="margin-top: 0.5rem; color: var(--accent-orange);">Q‚ÇÅ, K‚ÇÅ, V‚ÇÅ</div>
                    </div>
                    <div class="head-card">
                        <h4>Head 2</h4>
                        <div style="font-size: 0.8rem; color: var(--text-secondary);">dim: 8-11</div>
                        <div style="margin-top: 0.5rem; color: var(--accent-red);">Q‚ÇÇ, K‚ÇÇ, V‚ÇÇ</div>
                    </div>
                    <div class="head-card">
                        <h4>Head 3</h4>
                        <div style="font-size: 0.8rem; color: var(--text-secondary);">dim: 12-15</div>
                        <div style="margin-top: 0.5rem; color: var(--accent-blue);">Q‚ÇÉ, K‚ÇÉ, V‚ÇÉ</div>
                    </div>
                </div>

                <h3>üìè Scaled Dot-Product Attention</h3>
                <div class="equation">
                    Attention(Q, K, V) = softmax(QK<sup>T</sup> / ‚àöd<sub>k</sub>)V
                </div>
                <p>Scaling by ‚àöd<sub>k</sub> prevents the dot products from growing too large in high dimensions, which would push softmax into regions of extremely small gradients.</p>

                <h3>üéÆ Controls</h3>
                <div class="controls">
                    <button class="btn" onclick="animateAttention()">‚ñ∂Ô∏è Animate Attention Flow</button>
                    <button class="btn secondary" onclick="randomizeAttention()">üé≤ Randomize Weights</button>
                </div>
            </div>

            <!-- Training Tab -->
            <div id="training" class="tab-content">
                <h3>üèãÔ∏è Training Loop</h3>
                <p>The complete training pipeline for <span class="code-var">num_steps = 500</span> iterations.</p>

                <div class="flow-container">
                    <div class="flow-step" id="step1">
                        <div class="flow-step-number">1</div>
                        <div class="flow-step-content">
                            <div class="flow-step-title">Tokenization</div>
                            <div class="flow-step-desc">doc ‚Üí [BOS] + tokens + [BOS]</div>
                            <div class="code-snippet" style="margin: 0.5rem 0 0;">
tokens = [BOS] + [uchars.index(ch) for ch in doc] + [BOS]
                            </div>
                        </div>
                    </div>

                    <div class="flow-step" id="step2">
                        <div class="flow-step-number">2</div>
                        <div class="flow-step-content">
                            <div class="flow-step-title">Forward Pass</div>
                            <div class="flow-step-desc">gpt(token_id, pos_id, keys, values) ‚Üí logits</div>
                            <div class="code-snippet" style="margin: 0.5rem 0 0;">
for pos_id in range(n):
    logits = gpt(tokens[pos_id], pos_id, keys, values)
    probs = softmax(logits)
                            </div>
                        </div>
                    </div>

                    <div class="flow-step" id="step3">
                        <div class="flow-step-number">3</div>
                        <div class="flow-step-content">
                            <div class="flow-step-title">Loss Computation</div>
                            <div class="flow-step-desc">Cross-entropy: -log(prob[target])</div>
                            <div class="code-snippet" style="margin: 0.5rem 0 0;">
loss_t = -probs[target_id].log()
loss = (1/n) * sum(losses)
                            </div>
                        </div>
                    </div>

                    <div class="flow-step" id="step4">
                        <div class="flow-step-number">4</div>
                        <div class="flow-step-content">
                            <div class="flow-step-title">Backward Pass</div>
                            <div class="flow-step-desc">loss.backward() ‚Üí compute gradients</div>
                            <div class="code-snippet" style="margin: 0.5rem 0 0;">
loss.backward()  <span class="code-comment"># fills p.grad for all params</span>
                            </div>
                        </div>
                    </div>

                    <div class="flow-step" id="step5">
                        <div class="flow-step-number">5</div>
                        <div class="flow-step-content">
                            <div class="flow-step-title">Adam Optimizer Update</div>
                            <div class="flow-step-desc">p.data -= lr √ó mÃÇ / (‚àövÃÇ + Œµ)</div>
                            <div class="code-snippet" style="margin: 0.5rem 0 0;">
m = Œ≤‚ÇÅm + (1-Œ≤‚ÇÅ)grad
v = Œ≤‚ÇÇv + (1-Œ≤‚ÇÇ)grad¬≤
p.data -= lr √ó mÃÇ / (‚àövÃÇ + Œµ)
p.grad = 0
                            </div>
                        </div>
                    </div>
                </div>

                <h3>üìä Training Progress</h3>
                <div class="param-grid">
                    <div class="param-card">
                        <div class="param-name">learning_rate</div>
                        <div class="param-value">1e-2</div>
                    </div>
                    <div class="param-card">
                        <div class="param-name">beta1, beta2</div>
                        <div class="param-value">0.9, 0.95</div>
                    </div>
                    <div class="param-card">
                        <div class="param-name">num_steps</div>
                        <div class="param-value">500</div>
                    </div>
                    <div class="param-card">
                        <div class="param-name">temperature</div>
                        <div class="param-value">0.5</div>
                    </div>
                </div>

                <h3>üìà Cosine Learning Rate Schedule</h3>
                <div class="equation">
                    lr<sub>t</sub> = lr<sub>max</sub> √ó 0.5 √ó (1 + cos(œÄ √ó t / T))
                </div>
                <p>Gradually reduces learning rate from initial to near zero over training.</p>

                <div class="progress-container">
                    <div class="progress-bar" id="trainingProgress" style="width: 0%;">0/500</div>
                </div>

                <div style="margin-top: 1rem; padding: 1rem; background: var(--bg-primary); border-radius: 8px;">
                    <span style="color: var(--text-secondary);">Current Loss: </span>
                    <span id="lossDisplay" style="color: var(--accent-orange); font-weight: bold; font-size: 1.2rem;">---</span>
                </div>

                <h3>üéÆ Controls</h3>
                <div class="controls">
                    <button class="btn" onclick="animateTraining()">‚ñ∂Ô∏è Animate Training Loop</button>
                    <button class="btn secondary" onclick="resetTraining()">‚Ü∫ Reset</button>
                    <button class="btn secondary" onclick="runFullTraining()">‚è© Fast Training Demo</button>
                </div>
            </div>
        </section>

        <!-- Variables Reference Section -->
        <section class="section">
            <h2>üìö Variable Reference</h2>
            <p>Quick lookup for key variables matching the Python implementation.</p>

            <div class="param-grid">
                <div class="param-card">
                    <div class="param-name">wte</div>
                    <div style="color: var(--text-secondary); font-size: 0.85rem;">Token Embeddings</div>
                    <div class="param-value">27√ó16</div>
                </div>
                <div class="param-card">
                    <div class="param-name">wpe</div>
                    <div style="color: var(--text-secondary); font-size: 0.85rem;">Position Embeddings</div>
                    <div class="param-value">8√ó16</div>
                </div>
                <div class="param-card">
                    <div class="param-name">attn_wq</div>
                    <div style="color: var(--text-secondary); font-size: 0.85rem;">Attention Q proj</div>
                    <div class="param-value">16√ó16</div>
                </div>
                <div class="param-card">
                    <div class="param-name">attn_wk</div>
                    <div style="color: var(--text-secondary); font-size: 0.85rem;">Attention K proj</div>
                    <div class="param-value">16√ó16</div>
                </div>
                <div class="param-card">
                    <div class="param-name">attn_wv</div>
                    <div style="color: var(--text-secondary); font-size: 0.85rem;">Attention V proj</div>
                    <div class="param-value">16√ó16</div>
                </div>
                <div class="param-card">
                    <div class="param-name">attn_wo</div>
                    <div style="color: var(--text-secondary); font-size: 0.85rem;">Attention Output</div>
                    <div class="param-value">16√ó16</div>
                </div>
                <div class="param-card">
                    <div class="param-name">mlp_fc1</div>
                    <div style="color: var(--text-secondary); font-size: 0.85rem;">MLP expansion</div>
                    <div class="param-value">64√ó16</div>
                </div>
                <div class="param-card">
                    <div class="param-name">mlp_fc2</div>
                    <div style="color: var(--text-secondary); font-size: 0.85rem;">MLP projection</div>
                    <div class="param-value">16√ó64</div>
                </div>
                <div class="param-card">
                    <div class="param-name">lm_head</div>
                    <div style="color: var(--text-secondary); font-size: 0.85rem;">Language Model Head</div>
                    <div class="param-value">27√ó16</div>
                </div>
            </div>
        </section>

        <!-- Paper Architecture Comparison -->
        <section class="section">
            <h2>üîó Connection to "Attention Is All You Need" (2017)</h2>

            <h3>Architecture Mapping</h3>
            <table style="width: 100%; border-collapse: collapse; margin-top: 1rem;">
                <tr style="background: var(--bg-tertiary);">
                    <th style="padding: 1rem; text-align: left;">Paper Component</th>
                    <th style="padding: 1rem; text-align: left;">MicroGPT Variable</th>
                    <th style="padding: 1rem; text-align: left;">Notes</th>
                </tr>
                <tr>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">d<sub>model</sub></td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);"><span class="code-var">n_embd</span> = 16</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">Paper uses 512</td>
                </tr>
                <tr>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">h (heads)</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);"><span class="code-var">n_head</span> = 4</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">Paper uses 8</td>
                </tr>
                <tr>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">d<sub>k</sub> = d<sub>v</sub> = d<sub>model</sub>/h</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);"><span class="code-var">head_dim</span> = 4</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">16 / 4 = 4</td>
                </tr>
                <tr>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">d<sub>ff</sub></td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">4 √ó <span class="code-var">n_embd</span> = 64</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">Paper uses 4√ód<sub>model</sub></td>
                </tr>
                <tr>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">LayerNorm</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);"><span class="code-func">rmsnorm</span></td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">Simplified, no bias</td>
                </tr>
                <tr>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">Activation</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);"><span class="code-func">relu</span>¬≤</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">Paper uses ReLU (approx GeLU in later work)</td>
                </tr>
                <tr>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">N (layers)</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);"><span class="code-var">n_layer</span> = 1</td>
                    <td style="padding: 1rem; border-bottom: 1px solid var(--bg-tertiary);">Paper uses 6</td>
                </tr>
                <tr>
                    <td style="padding: 1rem;">Position Encoding</td>
                    <td style="padding: 1rem;"><span class="code-var">wpe</span> (learned)</td>
                    <td style="padding: 1rem;">Paper uses sinusoidal (learned in practice)</td>
                </tr>
            </table>

            <h3 style="margin-top: 2rem;">Key Differences from Paper</h3>
            <ul style="margin-top: 1rem; padding-left: 2rem; color: var(--text-secondary);">
                <li style="margin-bottom: 0.5rem;"><strong>Pre-LN vs Post-LN</strong>: MicroGPT uses pre-layer norm (like GPT-2), paper uses post-layer norm</li>
                <li style="margin-bottom: 0.5rem;"><strong>Decoder-only</strong>: MicroGPT is GPT-style decoder (causal mask), paper has encoder-decoder</li>
                <li style="margin-bottom: 0.5rem;"><strong>No biases</strong>: Simplified implementation, all linear layers are bias-free</li>
                <li style="margin-bottom: 0.5rem;"><strong>Activation</strong>: ReLU¬≤ approximates squared ReLU (similar to GeLU's shape)</li>
                <li><strong>Scale</strong>: Educational scale (tiny model) vs production scale</li>
            </ul>
        </section>
    </main>

    <footer>
        <p>Built for educational purposes ‚Ä¢ Based on <a href="microgpt.py" style="color: var(--accent-blue);">microgpt.py</a> by Andrej Karpathy</p>
        <p style="margin-top: 0.5rem;">Reference: <a href="https://arxiv.org/abs/1706.03762" target="_blank" style="color: var(--accent-blue);">Attention Is All You Need</a> (Vaswani et al., 2017)</p>
    </footer>

    <div class="tooltip" id="tooltip"></div>

    <script>
        // Tab switching
        document.querySelectorAll('.tab').forEach(tab => {
            tab.addEventListener('click', () => {
                document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
                document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));
                tab.classList.add('active');
                document.getElementById(tab.dataset.tab).classList.add('active');
            });
        });

        // Tooltip
        const tooltip = document.getElementById('tooltip');

        function showTooltip(e, content) {
            tooltip.innerHTML = content;
            tooltip.style.left = e.pageX + 10 + 'px';
            tooltip.style.top = e.pageY + 10 + 'px';
            tooltip.classList.add('show');
        }

        function hideTooltip() {
            tooltip.classList.remove('show');
        }

        document.addEventListener('mousemove', (e) => {
            if (tooltip.classList.contains('show')) {
                tooltip.style.left = e.pageX + 10 + 'px';
                tooltip.style.top = e.pageY + 10 + 'px';
            }
        });

        // Architecture Animation
        let architectureAnimationRunning = false;

        async function animateArchitecture() {
            if (architectureAnimationRunning) return;
            architectureAnimationRunning = true;

            const blocks = document.querySelectorAll('.arch-block');
            const order = ['input', 'embed', 'prenorm', 'attn', 'residual1', 'mlp', 'residual2', 'output'];

            resetArchitecture();

            for (const blockId of order) {
                const block = document.querySelector(`.arch-block[data-block="${blockId}"]`);
                if (block) {
                    block.classList.add('active', 'pulse');
                    await sleep(600);
                    block.classList.remove('pulse');
                }
            }

            architectureAnimationRunning = false;
        }

        function resetArchitecture() {
            document.querySelectorAll('.arch-block').forEach(b => {
                b.classList.remove('active', 'pulse');
            });
        }

        // Computation Graph
        function initComputationGraph() {
            const container = document.getElementById('computationGraph');
            container.innerHTML = '';

            const nodes = [
                { id: 'loss', x: 350, y: 50, label: 'Loss', type: 'loss' },
                { id: 'logits', x: 350, y: 150, label: 'logits', type: 'param' },
                { id: 'softmax', x: 350, y: 250, label: 'softmax', type: 'param' },
                { id: 'probs', x: 350, y: 350, label: 'probs', type: 'param' },
                { id: 'mlp_fc2', x: 550, y: 250, label: 'mlp_fc2', type: 'param' },
                { id: 'mlp_fc1', x: 550, y: 150, label: 'mlp_fc1', type: 'param' },
                { id: 'attn_wo', x: 150, y: 250, label: 'attn_wo', type: 'param' },
                { id: 'attn_wv', x: 150, y: 150, label: 'attn_wv', type: 'param' },
                { id: 'attn_wk', x: 150, y: 250, label: 'attn_wk', type: 'param' },
                { id: 'attn_wq', x: 150, y: 150, label: 'attn_wq', type: 'param' },
                { id: 'x', x: 250, y: 200, label: 'x', type: 'param' },
            ];

            const edges = [
                ['loss', 'logits'],
                ['logits', 'softmax'],
                ['softmax', 'probs'],
                ['probs', 'x'],
                ['mlp_fc2', 'mlp_fc1'],
                ['mlp_fc1', 'x'],
                ['attn_wo', 'attn_wq'],
                ['attn_wo', 'attn_wk'],
                ['attn_wo', 'attn_wv'],
                ['attn_wq', 'x'],
                ['attn_wk', 'x'],
                ['attn_wv', 'x'],
            ];

            // Draw edges
            edges.forEach(([from, to]) => {
                const fromNode = nodes.find(n => n.id === from);
                const toNode = nodes.find(n => n.id === to);
                if (fromNode && toNode) {
                    const edge = document.createElement('div');
                    edge.className = 'graph-edge';

                    const dx = toNode.x - fromNode.x;
                    const dy = toNode.y - fromNode.y;
                    const length = Math.sqrt(dx * dx + dy * dy);
                    const angle = Math.atan2(dy, dx) * 180 / Math.PI;

                    edge.style.width = length + 'px';
                    edge.style.left = fromNode.x + 40 + 'px';
                    edge.style.top = fromNode.y + 40 + 'px';
                    edge.style.transform = `rotate(${angle}deg)`;

                    container.appendChild(edge);
                }
            });

            // Draw nodes
            nodes.forEach(node => {
                const el = document.createElement('div');
                el.className = `graph-node ${node.type}`;
                el.style.left = node.x + 'px';
                el.style.top = node.y + 'px';
                el.textContent = node.label;
                el.dataset.id = node.id;

                el.addEventListener('click', () => showGradientInfo(node));
                el.addEventListener('mouseenter', (e) => {
                    showTooltip(e, `<strong>${node.label}</strong><br>‚àÇL/‚àÇ${node.id} = ${node.type === 'loss' ? 1 : (Math.random() * 0.1).toFixed(4)}`);
                });
                el.addEventListener('mouseleave', hideTooltip);

                container.appendChild(el);
            });
        }

        function showGradientInfo(node) {
            const gradientDisplay = document.getElementById('gradientInfo');
            const gradValue = node.type === 'loss' ? '1.0000' : (Math.random() * 0.1).toFixed(4);
            gradientDisplay.innerHTML = `
                <strong style="color: var(--accent-blue);">‚àÇL/‚àÇ${node.id}</strong> = ${gradValue}<br>
                <span style="color: var(--text-secondary); font-size: 0.85rem;">
                Chain rule: gradient flows through children in topological order
                </span>
            `;

            // Highlight node
            document.querySelectorAll('.graph-node').forEach(n => n.classList.remove('active'));
            document.querySelector(`.graph-node[data-id="${node.id}"]`)?.classList.add('active');
        }

        async function animateBackprop() {
            const nodes = document.querySelectorAll('.graph-node');
            const order = ['loss', 'logits', 'softmax', 'probs', 'x', 'attn_wq', 'attn_wk', 'attn_wv', 'attn_wo', 'mlp_fc1', 'mlp_fc2'];

            for (const nodeId of order) {
                const node = document.querySelector(`.graph-node[data-id="${nodeId}"]`);
                if (node) {
                    node.classList.add('active', 'pulse');
                    showGradientInfo({ id: nodeId, type: nodeId === 'loss' ? 'loss' : 'param' });
                    await sleep(400);
                    node.classList.remove('pulse');
                }
            }
        }

        function resetGraph() {
            initComputationGraph();
            document.getElementById('gradientInfo').innerHTML = 'Hover over or click a node to see gradient information...';
        }

        // Attention Grid
        function initAttentionGrid() {
            const grid = document.getElementById('attentionGrid');
            grid.innerHTML = '';

            for (let t = 0; t < 8; t++) {
                for (let tau = 0; tau < 8; tau++) {
                    const cell = document.createElement('div');
                    cell.className = 'attention-cell';
                    cell.dataset.t = t;
                    cell.dataset.tau = tau;

                    // Causal mask: can only attend to tau <= t
                    const isAttended = tau <= t;
                    const weight = isAttended ? Math.exp(-Math.abs(t - tau) * 0.5) : 0;
                    const normalized = isAttended ? weight / Array.from({length: t + 1}, (_, i) => Math.exp(-Math.abs(t - i) * 0.5)).reduce((a, b) => a + b, 0) : 0;

                    const intensity = Math.floor(normalized * 255);
                    cell.style.backgroundColor = isAttended
                        ? `rgb(${intensity}, ${intensity}, ${intensity + 50})`
                        : 'var(--bg-tertiary)';

                    cell.textContent = isAttended ? normalized.toFixed(2) : '';

                    cell.addEventListener('mouseenter', (e) => {
                        showTooltip(e, `
                            <strong>Attention(t=${t}, œÑ=${tau})</strong><br>
                            Weight: ${normalized.toFixed(4)}<br>
                            ${tau <= t ? '‚úì Attended (causal mask)' : '‚úó Masked (future token)'}
                        `);
                    });
                    cell.addEventListener('mouseleave', hideTooltip);

                    grid.appendChild(cell);
                }
            }
        }

        async function animateAttention() {
            const cells = document.querySelectorAll('.attention-cell');
            cells.forEach(c => c.classList.remove('pulse'));

            for (let t = 0; t < 8; t++) {
                for (let tau = 0; tau <= t; tau++) {
                    const cell = document.querySelector(`.attention-cell[data-t="${t}"][data-tau="${tau}"]`);
                    if (cell) {
                        cell.classList.add('pulse');
                        await sleep(100);
                        cell.classList.remove('pulse');
                    }
                }
            }
        }

        function randomizeAttention() {
            const cells = document.querySelectorAll('.attention-cell');
            cells.forEach(cell => {
                const t = parseInt(cell.dataset.t);
                const tau = parseInt(cell.dataset.tau);
                const isAttended = tau <= t;

                if (isAttended) {
                    const weight = Math.random();
                    cell.style.backgroundColor = `rgb(${Math.floor(weight * 255)}, ${Math.floor(weight * 200)}, ${Math.floor(weight * 100 + 50)})`;
                    cell.textContent = weight.toFixed(2);
                }
            });
        }

        // Training Animation
        let trainingAnimationRunning = false;

        async function animateTraining() {
            if (trainingAnimationRunning) return;
            trainingAnimationRunning = true;

            const steps = ['step1', 'step2', 'step3', 'step4', 'step5'];
            const losses = [3.2, 2.8, 2.5, 2.2, 1.9, 1.7, 1.5, 1.3, 1.2, 1.1];

            for (let i = 0; i < losses.length; i++) {
                const stepIndex = i % steps.length;
                const stepId = steps[stepIndex];

                document.querySelectorAll('.flow-step').forEach(s => s.classList.remove('active'));
                document.getElementById(stepId)?.classList.add('active');

                const loss = losses[i] - (Math.random() * 0.1);
                document.getElementById('lossDisplay').textContent = loss.toFixed(4);

                const progress = ((i + 1) / losses.length) * 100;
                const progressBar = document.getElementById('trainingProgress');
                progressBar.style.width = progress + '%';
                progressBar.textContent = `${Math.floor(progress * 5 / 100)}/${losses.length}`;

                await sleep(800);
            }

            trainingAnimationRunning = false;
        }

        function resetTraining() {
            document.querySelectorAll('.flow-step').forEach(s => s.classList.remove('active'));
            document.getElementById('trainingProgress').style.width = '0%';
            document.getElementById('trainingProgress').textContent = '0/500';
            document.getElementById('lossDisplay').textContent = '---';
        }

        async function runFullTraining() {
            if (trainingAnimationRunning) return;
            trainingAnimationRunning = true;

            const progressBar = document.getElementById('trainingProgress');
            const lossDisplay = document.getElementById('lossDisplay');

            for (let step = 0; step <= 500; step += 10) {
                const progress = (step / 500) * 100;
                const loss = 3.5 * Math.exp(-step / 100) + 0.5 + Math.random() * 0.1;

                progressBar.style.width = progress + '%';
                progressBar.textContent = `${step}/${500}`;
                lossDisplay.textContent = loss.toFixed(4);

                await sleep(20);
            }

            trainingAnimationRunning = false;
        }

        // Utility
        function sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }

        // Initialize on load
        document.addEventListener('DOMContentLoaded', () => {
            initComputationGraph();
            initAttentionGrid();
        });
    </script>
</body>
</html>
