<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MicroGPT - Educational Visualization</title>
    <style>
        :root {
            --bg-primary: #0f172a;
            --bg-secondary: #1e293b;
            --bg-tertiary: #334155;
            --text-primary: #f1f5f9;
            --text-secondary: #94a3b8;
            --accent-blue: #3b82f6;
            --accent-purple: #8b5cf6;
            --accent-green: #10b981;
            --accent-orange: #f97316;
            --accent-red: #ef4444;
            --accent-yellow: #eab308;
            --code-bg: #1a1a2e;
            --code-highlight: #3b82f633;
            --code-line-number: #475569;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.6;
            height: 100vh;
            display: flex;
            flex-direction: column;
        }

        header {
            background: linear-gradient(135deg, var(--bg-secondary) 0%, var(--bg-tertiary) 100%);
            padding: 1rem 2rem;
            border-bottom: 2px solid var(--accent-blue);
            flex-shrink: 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        header .header-left {
            flex: 1;
        }

        header h1 {
            font-size: 1.8rem;
            margin-bottom: 0.25rem;
            background: linear-gradient(135deg, var(--accent-blue), var(--accent-purple));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        header p {
            color: var(--text-secondary);
            font-size: 0.9rem;
        }

        .paper-link {
            display: inline-block;
            padding: 0.4rem 0.8rem;
            background: var(--accent-blue);
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-size: 0.85rem;
            transition: all 0.3s ease;
        }

        .paper-link:hover {
            background: var(--accent-purple);
            transform: translateY(-2px);
        }

        /* Split Pane Layout */
        .split-container {
            display: flex;
            flex: 1;
            overflow: hidden;
        }

        .left-panel {
            flex: 1;
            overflow-y: auto;
            padding: 1rem;
            border-right: 2px solid var(--bg-tertiary);
            min-width: 400px;
        }

        .right-panel {
            flex: 1;
            overflow-y: auto;
            background: var(--code-bg);
            min-width: 500px;
            position: relative;
        }

        main {
            max-width: 100%;
        }

        /* Code Viewer */
        .code-viewer {
            position: relative;
            padding: 1rem 0;
        }

        .code-line {
            display: flex;
            padding: 2px 0;
            font-family: 'Fira Code', 'Consolas', 'Monaco', monospace;
            font-size: 13px;
            line-height: 1.5;
            transition: all 0.3s ease;
        }

        .code-line.highlighted {
            background: var(--code-highlight);
        }

        .code-line-number {
            min-width: 50px;
            text-align: right;
            padding-right: 1rem;
            color: var(--code-line-number);
            user-select: none;
            border-right: 1px solid var(--bg-tertiary);
            margin-right: 1rem;
        }

        .code-line-content {
            flex: 1;
            padding: 0 1rem;
            white-space: pre-wrap;
            word-break: break-all;
        }

        /* Python Syntax Highlighting */
        .py-keyword { color: #c792ea; }
        .py-function { color: #82aaff; }
        .py-class { color: #ffcb6b; }
        .py-string { color: #c3e88d; }
        .py-number { color: #f78c6c; }
        .py-comment { color: #546e7a; font-style: italic; }
        .py-operator { color: #89ddff; }
        .py-builtin { color: #f07178; }
        .py-variable { color: #f1f5f9; }
        .py-decorator { color: #c792ea; }
        .py-annotation { color: #ffcb6b; }

        .section {
            background: var(--bg-secondary);
            border-radius: 12px;
            padding: 1rem;
            margin-bottom: 1rem;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
        }

        .section h2 {
            color: var(--accent-blue);
            margin-bottom: 1rem;
            font-size: 1.3rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .section h3 {
            color: var(--accent-purple);
            margin: 1rem 0 0.5rem;
            font-size: 1.1rem;
        }

        .section p {
            color: var(--text-secondary);
            margin-bottom: 0.5rem;
            font-size: 0.9rem;
        }

        .code-snippet {
            background: var(--bg-primary);
            border-radius: 6px;
            padding: 0.75rem;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.8rem;
            overflow-x: auto;
            border-left: 3px solid var(--accent-green);
            margin: 0.5rem 0;
        }

        .code-var {
            color: var(--accent-blue);
        }

        .code-func {
            color: var(--accent-purple);
        }

        .code-comment {
            color: var(--text-secondary);
            font-style: italic;
        }

        /* Architecture Diagram */
        .arch-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem;
        }

        .arch-block {
            background: var(--bg-tertiary);
            border: 2px solid var(--accent-blue);
            border-radius: 10px;
            padding: 0.75rem 1rem;
            min-width: 200px;
            text-align: center;
            position: relative;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .arch-block:hover {
            border-color: var(--accent-purple);
            transform: scale(1.02);
            box-shadow: 0 0 15px rgba(139, 92, 246, 0.3);
        }

        .arch-block.active {
            background: linear-gradient(135deg, var(--accent-blue), var(--accent-purple));
            border-color: var(--accent-green);
        }

        .arch-block .block-name {
            font-weight: bold;
            font-size: 1rem;
        }

        .arch-block .block-var {
            color: var(--accent-yellow);
            font-family: monospace;
            font-size: 0.8rem;
        }

        .arch-arrow {
            font-size: 1.5rem;
            color: var(--accent-blue);
        }

        .arch-row {
            display: flex;
            gap: 0.5rem;
            align-items: center;
        }

        /* Tabs */
        .tabs {
            display: flex;
            gap: 0.25rem;
            margin-bottom: 0.5rem;
            border-bottom: 2px solid var(--accent-blue);
            flex-wrap: wrap;
        }

        .tab {
            padding: 0.5rem 1rem;
            background: transparent;
            color: var(--text-secondary);
            border: none;
            cursor: pointer;
            font-size: 0.9rem;
            transition: all 0.3s ease;
        }

        .tab:hover {
            color: var(--text-primary);
        }

        .tab.active {
            color: var(--accent-blue);
            border-bottom: 3px solid var(--accent-blue);
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        /* Controls */
        .controls {
            display: flex;
            gap: 0.5rem;
            margin-top: 0.5rem;
            flex-wrap: wrap;
        }

        .btn {
            padding: 0.5rem 1rem;
            background: var(--accent-blue);
            color: white;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: all 0.3s ease;
        }

        .btn:hover {
            background: var(--accent-purple);
            transform: translateY(-2px);
        }

        .btn.secondary {
            background: var(--bg-tertiary);
            border: 1px solid var(--accent-blue);
        }

        .btn.secondary:hover {
            background: var(--accent-blue);
        }

        /* Animation */
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .pulse {
            animation: pulse 1s ease-in-out infinite;
        }

        /* Tooltip */
        .tooltip {
            position: fixed;
            background: var(--bg-tertiary);
            border: 1px solid var(--accent-blue);
            border-radius: 8px;
            padding: 0.5rem;
            font-size: 0.8rem;
            max-width: 250px;
            z-index: 1000;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.2s ease;
        }

        .tooltip.show {
            opacity: 1;
        }

        /* Code header */
        .code-header {
            position: sticky;
            top: 0;
            background: var(--bg-tertiary);
            padding: 0.5rem 1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid var(--accent-blue);
            z-index: 100;
        }

        .code-header h3 {
            margin: 0;
            font-size: 1rem;
            color: var(--accent-blue);
        }

        .code-header-actions {
            display: flex;
            gap: 0.5rem;
        }

        .code-header-actions button {
            padding: 0.25rem 0.5rem;
            font-size: 0.8rem;
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .split-container {
                flex-direction: column;
            }

            .left-panel, .right-panel {
                min-width: auto;
                max-height: 50vh;
            }

            header h1 {
                font-size: 1.3rem;
            }
        }

        /* Scrollbar styling */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-primary);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--bg-tertiary);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--accent-blue);
        }

        /* Attention Grid */
        .attention-grid {
            display: grid;
            grid-template-columns: repeat(8, 1fr);
            gap: 2px;
            max-width: 300px;
            margin: 0.5rem auto;
        }

        .attention-cell {
            aspect-ratio: 1;
            background: var(--bg-tertiary);
            border-radius: 3px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.6rem;
            font-family: monospace;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .attention-cell:hover {
            transform: scale(1.2);
            z-index: 10;
        }

        /* Parameter Grid */
        .param-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
            gap: 0.5rem;
        }

        .param-card {
            background: var(--bg-primary);
            border: 1px solid var(--accent-blue);
            border-radius: 8px;
            padding: 0.5rem;
            text-align: center;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .param-card:hover {
            border-color: var(--accent-purple);
            transform: translateY(-2px);
            box-shadow: 0 2px 10px rgba(139, 92, 246, 0.3);
        }

        .param-card .param-name {
            color: var(--accent-green);
            font-family: monospace;
            font-size: 0.95rem;
            margin-bottom: 0.25rem;
        }

        .param-card .param-value {
            color: var(--accent-orange);
            font-size: 1.1rem;
            font-weight: bold;
        }

        .github-link, .github-button {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 8px 16px;
            background: #24292e;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-size: 14px;
            transition: background 0.2s;
        }

    .github-link:hover, .github-button:hover {
        background: #2c3e50;
    }
    </style>
</head>
<body>
    <header>
        <div class="header-left">
            <h1>üß† MicroGPT Visualization</h1>
            <p>Interactive educational guide ‚Ä¢ Click architecture blocks to see code</p>
        </div>
        <div>
            <p>
                <a href="https://github.com/tanpuekai/microGPT_webEdu" target="_blank" class="paper-link">
                    <b>GitHub</b> peikaichen/microGPT_webEdu
                </a>
            </p>
        </div>

    </header>

    <div class="split-container">
        <div class="left-panel">
            <main>
                <!-- Architecture Tab -->
                <section class="section">
                    <div class="tabs">
                        <button class="tab active" data-tab="architecture">Architecture</button>
                        <button class="tab" data-tab="autograd">Autograd</button>
                        <button class="tab" data-tab="attention">Attention</button>
                        <button class="tab" data-tab="training">Training</button>
                    </div>

                    <div id="architecture" class="tab-content active">
                        <h3>üèóÔ∏è Model Architecture</h3>
                        <p>Click blocks to jump to code</p>

                        <div class="arch-container">
                            <div class="arch-row">
                                <div class="arch-block" data-block="input" data-lines="156-158">
                                    <div class="block-name">Input</div>
                                    <div class="block-var">token_id, pos_id</div>
                                </div>
                                <div class="arch-arrow">‚Üí</div>
                                <div class="arch-block" data-block="embed" data-lines="74-86,109-111">
                                    <div class="block-name">Embeddings</div>
                                    <div class="block-var">wte, wpe</div>
                                </div>
                            </div>

                            <div class="arch-arrow">‚Üì</div>

                            <div class="arch-block" data-block="prenorm" data-lines="103-106,112">
                                <div class="block-name">Pre-Norm</div>
                                <div class="block-var">rmsnorm(x)</div>
                            </div>

                            <div class="arch-arrow">‚Üì</div>

                            <div class="arch-row">
                                <div class="arch-block" data-block="attn" data-lines="118-133">
                                    <div class="block-name">Multi-Head Attention</div>
                                    <div class="block-var">attn_wq, attn_wk, attn_wv, attn_wo</div>
                                </div>
                                <div class="arch-arrow">+</div>
                                <div class="arch-block" data-block="residual1" data-lines="116,134">
                                    <div class="block-name">Residual</div>
                                    <div class="block-var">x + x_attn</div>
                                </div>
                            </div>

                            <div class="arch-arrow">‚Üì</div>

                            <div class="arch-row">
                                <div class="arch-block" data-block="mlp" data-lines="136-141">
                                    <div class="block-name">MLP</div>
                                    <div class="block-var">mlp_fc1, ReLU¬≤, mlp_fc2</div>
                                </div>
                                <div class="arch-arrow">+</div>
                                <div class="arch-block" data-block="residual2" data-lines="136,141">
                                    <div class="block-name">Residual</div>
                                    <div class="block-var">x + x_mlp</div>
                                </div>
                            </div>

                            <div class="arch-arrow">‚Üì</div>

                            <div class="arch-block" data-block="output" data-lines="143">
                                <div class="block-name">Output</div>
                                <div class="block-var">logits = lm_head(x)</div>
                            </div>
                        </div>

                        <h3>üìä Parameters (click to jump)</h3>
                        <div class="param-grid">
                            <div class="param-card" data-lines="14-27,74-86">
                                <div class="param-name">vocab_size</div>
                                <div class="param-value">27</div>
                            </div>
                            <div class="param-card" data-lines="75">
                                <div class="param-name">n_embd</div>
                                <div class="param-value">16</div>
                            </div>
                            <div class="param-card" data-lines="76">
                                <div class="param-name">n_head</div>
                                <div class="param-value">4</div>
                            </div>
                            <div class="param-card" data-lines="77">
                                <div class="param-name">n_layer</div>
                                <div class="param-value">1</div>
                            </div>
                            <div class="param-card" data-lines="78">
                                <div class="param-name">block_size</div>
                                <div class="param-value">8</div>
                            </div>
                            <div class="param-card" data-lines="81">
                                <div class="param-name">wte, wpe</div>
                                <div class="param-value">embed</div>
                            </div>
                            <div class="param-card" data-lines="83-86">
                                <div class="param-name">attn_*</div>
                                <div class="param-value">attn</div>
                            </div>
                            <div class="param-card" data-lines="87-88">
                                <div class="param-name">mlp_*</div>
                                <div class="param-value">mlp</div>
                            </div>
                        </div>

                        <div class="controls">
                            <button class="btn" onclick="animateArchitecture()">‚ñ∂Ô∏è Animate Forward</button>
                        </div>
                    </div>

                    <div id="autograd" class="tab-content">
                        <h3>üîÑ Value Class - Autograd</h3>
                        <div class="arch-block" data-block="value" data-lines="30-72" style="margin: 0.5rem auto; min-width: 250px;">
                            <div class="block-name">Value Class</div>
                            <div class="block-var">class Value</div>
                        </div>

                        <h3>üìà Key Methods</h3>
                        <div class="param-grid">
                            <div class="param-card" data-lines="33-37">
                                <div class="param-name">__init__</div>
                                <div class="param-value">init</div>
                            </div>
                            <div class="param-card" data-lines="39-41">
                                <div class="param-name">__add__</div>
                                <div class="param-value">+</div>
                            </div>
                            <div class="param-card" data-lines="43-45">
                                <div class="param-name">__mul__</div>
                                <div class="param-value">√ó</div>
                            </div>
                            <div class="param-card" data-lines="47-50">
                                <div class="param-name">log, exp</div>
                                <div class="param-value">math</div>
                            </div>
                            <div class="param-card" data-lines="50">
                                <div class="param-name">relu</div>
                                <div class="param-value">act</div>
                            </div>
                            <div class="param-card" data-lines="59-72">
                                <div class="param-name">backward</div>
                                <div class="param-value">backprop</div>
                            </div>
                        </div>

                        <h3>üîó Chain Rule</h3>
                        <div class="code-snippet" style="font-size: 0.75rem;">
‚àÇL/‚àÇx = Œ£ (‚àÇL/‚àÇy) √ó (‚àÇy/‚àÇx)<br>
Topological sort ‚Üí gradient accumulation
                        </div>

                        <div class="controls">
                            <button class="btn" data-lines="59-72">‚ñ∂Ô∏è Show backward()</button>
                        </div>
                    </div>

                    <div id="attention" class="tab-content">
                        <h3>üëÅÔ∏è Multi-Head Attention</h3>
                        <div class="arch-block" data-block="attn-code" data-lines="118-133" style="margin: 0.5rem auto; min-width: 250px;">
                            <div class="block-name">Attention Loop</div>
                            <div class="block-var">lines 118-133</div>
                        </div>

                        <h3>üéØ Attention Pattern</h3>
                        <div class="attention-grid" id="attentionGrid"></div>

                        <h3>üß© Head Structure</h3>
                        <div class="param-grid">
                            <div class="param-card" data-lines="124">
                                <div class="param-name">Query (q_h)</div>
                                <div class="param-value">lines 124</div>
                            </div>
                            <div class="param-card" data-lines="125">
                                <div class="param-name">Keys (k_h)</div>
                                <div class="param-value">line 125</div>
                            </div>
                            <div class="param-card" data-lines="126">
                                <div class="param-name">Values (v_h)</div>
                                <div class="param-value">line 126</div>
                            </div>
                            <div class="param-card" data-lines="129">
                                <div class="param-name">Softmax</div>
                                <div class="param-value">line 129</div>
                            </div>
                        </div>

                        <div class="controls">
                            <button class="btn" onclick="animateAttention()">‚ñ∂Ô∏è Animate</button>
                            <button class="btn secondary" onclick="randomizeAttention()">üé≤ Randomize</button>
                        </div>
                    </div>

                    <div id="training" class="tab-content">
                        <h3>üèãÔ∏è Training Loop</h3>
                        <p>Click steps to see code</p>

                        <div class="arch-container">
                            <div class="arch-block" data-block="tokenize" data-lines="155-158">
                                <div class="block-name">1. Tokenize</div>
                                <div class="block-var">lines 155-158</div>
                            </div>
                            <div class="arch-arrow">‚Üì</div>
                            <div class="arch-block" data-block="forward" data-lines="161-169">
                                <div class="block-name">2. Forward</div>
                                <div class="block-var">lines 161-169</div>
                            </div>
                            <div class="arch-arrow">‚Üì</div>
                            <div class="arch-block" data-block="loss" data-lines="167-169">
                                <div class="block-name">3. Loss</div>
                                <div class="block-var">lines 167-169</div>
                            </div>
                            <div class="arch-arrow">‚Üì</div>
                            <div class="arch-block" data-block="backward" data-lines="172">
                                <div class="block-name">4. Backward</div>
                                <div class="block-var">line 172</div>
                            </div>
                            <div class="arch-arrow">‚Üì</div>
                            <div class="arch-block" data-block="adam" data-lines="176-182">
                                <div class="block-name">5. Adam Update</div>
                                <div class="block-var">lines 176-182</div>
                            </div>
                        </div>

                        <h3>üìä Hyperparameters</h3>
                        <div class="param-grid">
                            <div class="param-card" data-lines="147">
                                <div class="param-name">lr</div>
                                <div class="param-value">1e-2</div>
                            </div>
                            <div class="param-card" data-lines="147">
                                <div class="param-name">beta1,2</div>
                                <div class="param-value">0.9,0.95</div>
                            </div>
                            <div class="param-card" data-lines="152">
                                <div class="param-name">steps</div>
                                <div class="param-value">500</div>
                            </div>
                            <div class="param-card" data-lines="187">
                                <div class="param-name">temp</div>
                                <div class="param-value">0.5</div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Functions Reference -->
                <section class="section">
                    <h3>üîß Quick Functions</h3>
                    <div class="param-grid">
                        <div class="param-card" data-lines="94-95">
                            <div class="param-name">linear()</div>
                            <div class="param-value">lines 94-95</div>
                        </div>
                        <div class="param-card" data-lines="97-101">
                            <div class="param-name">softmax()</div>
                            <div class="param-value">lines 97-101</div>
                        </div>
                        <div class="param-card" data-lines="103-106">
                            <div class="param-name">rmsnorm()</div>
                            <div class="param-value">lines 103-106</div>
                        </div>
                        <div class="param-card" data-lines="108-144">
                            <div class="param-name">gpt()</div>
                            <div class="param-value">lines 108-144</div>
                        </div>
                    </div>
                </section>
            </main>
        </div>

        <div class="right-panel">
            <div class="code-header">
                <h3>üìÑ microgpt.py</h3>
                <div class="code-header-actions">
                    <button class="btn secondary" onclick="scrollToTop()">‚¨ÜÔ∏è Top</button>
                </div>
            </div>
            <div class="code-viewer" id="codeViewer">
                <!-- Code will be loaded here -->
            </div>
        </div>
    </div>

    <div class="tooltip" id="tooltip"></div>

    <script>
        // Python code content with syntax highlighting
        const pythonCode = `"""
The most atomic way to train and inference a GPT in pure, dependency-free Python.
This file is the complete algorithm.
Everything else is just efficiency.

@karpathy
"""

import os       # os.path.exists
import math     # math.log, math.exp
import random   # random.seed, random.choices, random.gauss, random.shuffle
random.seed(42) # Let there be order among chaos

# Let there be an input dataset \`docs\`: list[str] of documents (e.g. a dataset of names)
if not os.path.exists('input.txt'):
    import urllib.request
    names_url = 'https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt'
    urllib.request.urlretrieve(names_url, 'input.txt')
docs = [l.strip() for l in open('input.txt').read().strip().split('\\n') if l.strip()] # list[str] of documents
random.shuffle(docs)
print(f"num docs: {len(docs)}")

# Let there be a Tokenizer to translate strings to discrete symbols and back
uchars = sorted(set(''.join(docs))) # unique characters in the dataset become token ids 0..n-1
BOS = len(uchars) # token id for the special Beginning of Sequence (BOS) token
vocab_size = len(uchars) + 1 # total number of unique tokens, +1 is for BOS
print(f"vocab size: {vocab_size}")

# Let there be an Autograd to apply the chain rule recursively across a computation graph
class Value:
    """Stores a single scalar value and its gradient, as a node in a computation graph."""

    def __init__(self, data, children=(), local_grads=()):
        self.data = data                # scalar value of this node calculated during forward pass
        self.grad = 0                   # derivative of the loss w.r.t. this node, calculated in backward pass
        self._children = children       # children of this node in the computation graph
        self._local_grads = local_grads # local derivative of this node w.r.t. its children

    def __add__(self, other):
        other = other if isinstance(other, Value) else Value(other)
        return Value(self.data + other.data, (self, other), (1, 1))

    def __mul__(self, other):
        other = other if isinstance(other, Value) else Value(other)
        return Value(self.data * other.data, (self, other), (other.data, self.data))

    def __pow__(self, other): return Value(self.data**other, (self,), (other * self.data**(other-1),))
    def log(self): return Value(math.log(self.data), (self,), (1/self.data,))
    def exp(self): return Value(math.exp(self.data), (self,), (math.exp(self.data),))
    def relu(self): return Value(max(0, self.data), (self,), (float(self.data > 0),))
    def __neg__(self): return self * -1
    def __radd__(self, other): return self + other
    def __sub__(self, other): return self + (-other)
    def __rsub__(self, other): return other + (-self)
    def __rmul__(self, other): return self * other
    def __truediv__(self, other): return self * other**-1
    def __rtruediv__(self, other): return other * self**-1

    def backward(self):
        topo = []
        visited = set()
        def build_topo(v):
            if v not in visited:
                visited.add(v)
                for child in v._children:
                    build_topo(child)
                topo.append(v)
        build_topo(self)
        self.grad = 1
        for v in reversed(topo):
            for child, local_grad in zip(v._children, v._local_grads):
                child.grad += local_grad * v.grad

# Initialize the parameters, to store the knowledge of the model.
n_embd = 16     # embedding dimension
n_head = 4      # number of attention heads
n_layer = 1     # number of layers
block_size = 8  # maximum sequence length
head_dim = n_embd // n_head # dimension of each head
matrix = lambda nout, nin, std=0.02: [[Value(random.gauss(0, std)) for _ in range(nin)] for _ in range(nout)]
state_dict = {'wte': matrix(vocab_size, n_embd), 'wpe': matrix(block_size, n_embd), 'lm_head': matrix(vocab_size, n_embd)}
for i in range(n_layer):
    state_dict[f'layer{i}.attn_wq'] = matrix(n_embd, n_embd)
    state_dict[f'layer{i}.attn_wk'] = matrix(n_embd, n_embd)
    state_dict[f'layer{i}.attn_wv'] = matrix(n_embd, n_embd)
    state_dict[f'layer{i}.attn_wo'] = matrix(n_embd, n_embd, std=0)
    state_dict[f'layer{i}.mlp_fc1'] = matrix(4 * n_embd, n_embd)
    state_dict[f'layer{i}.mlp_fc2'] = matrix(n_embd, 4 * n_embd, std=0)
params = [p for mat in state_dict.values() for row in mat for p in row] # flatten params into a single list[Value]
print(f"num params: {len(params)}")

# Define the model architecture: a stateless function mapping token sequence and parameters to logits over what comes next.
# Follow GPT-2, blessed among the GPTs, with minor differences: layernorm -> rmsnorm, no biases, GeLU -> ReLU^2
def linear(x, w):
    return [sum(wi * xi for wi, xi in zip(wo, x)) for wo in w]

def softmax(logits):
    max_val = max(val.data for val in logits)
    exps = [(val - max_val).exp() for val in logits]
    total = sum(exps)
    return [e / total for e in exps]

def rmsnorm(x):
    ms = sum(xi * xi for xi in x) / len(x)
    scale = (ms + 1e-5) ** -0.5
    return [xi * scale for xi in x]

def gpt(token_id, pos_id, keys, values):
    tok_emb = state_dict['wte'][token_id] # token embedding
    pos_emb = state_dict['wpe'][pos_id] # position embedding
    x = [t + p for t, p in zip(tok_emb, pos_emb)] # joint token and position embedding
    x = rmsnorm(x)

    for li in range(n_layer):
        # 1) Multi-head attention block
        x_residual = x
        x = rmsnorm(x)
        q = linear(x, state_dict[f'layer{li}.attn_wq'])
        k = linear(x, state_dict[f'layer{li}.attn_wk'])
        v = linear(x, state_dict[f'layer{li}.attn_wv'])
        keys[li].append(k)
        values[li].append(v)
        x_attn = []
        for h in range(n_head):
            hs = h * head_dim
            q_h = q[hs:hs+head_dim]
            k_h = [ki[hs:hs+head_dim] for ki in keys[li]]
            v_h = [vi[hs:hs+head_dim] for vi in values[li]]
            attn_logits = [sum(q_h[j] * k_h[t][j] for j in range(head_dim)) / head_dim**0.5 for t in range(len(k_h))]
            attn_weights = softmax(attn_logits)
            head_out = [sum(attn_weights[t] * v_h[t][j] for t in range(len(v_h))) for j in range(head_dim)]
            x_attn.extend(head_out)
        x = linear(x_attn, state_dict[f'layer{li}.attn_wo'])
        x = [a + b for a, b in zip(x, x_residual)]
        # 2) MLP block
        x_residual = x
        x = rmsnorm(x)
        x = linear(x, state_dict[f'layer{li}.mlp_fc1'])
        x = [xi.relu() ** 2 for xi in x]
        x = linear(x, state_dict[f'layer{li}.mlp_fc2'])
        x = [a + b for a, b in zip(x, x_residual)]

    logits = linear(x, state_dict['lm_head'])
    return logits

# Let there be Adam, the blessed optimizer and its buffers
learning_rate, beta1, beta2, eps_adam = 1e-2, 0.9, 0.95, 1e-8
m = [0.0] * len(params) # first moment buffer
v = [0.0] * len(params) # second moment buffer

# Repeat in sequence
num_steps = 500 # number of training steps
for step in range(num_steps):

    # Take single document, tokenize it, surround it with BOS special token on both sides
    doc = docs[step % len(docs)]
    tokens = [BOS] + [uchars.index(ch) for ch in doc] + [BOS]
    n = min(block_size, len(tokens) - 1)

    # Forward the token sequence through the model, building up the computation graph all the way to the loss.
    keys, values = [[] for _ in range(n_layer)], [[] for _ in range(n_layer)]
    losses = []
    for pos_id in range(n):
        token_id, target_id = tokens[pos_id], tokens[pos_id + 1]
        logits = gpt(token_id, pos_id, keys, values)
        probs = softmax(logits)
        loss_t = -probs[target_id].log()
        losses.append(loss_t)
    loss = (1 / n) * sum(losses) # final average loss over the document sequence. May yours be low.

    # Backward the loss, calculating the gradients with respect to all model parameters.
    loss.backward()

    # Adam optimizer update: update the model parameters based on the corresponding gradients.
    lr_t = learning_rate * 0.5 * (1 + math.cos(math.pi * step / num_steps)) # cosine learning rate decay
    for i, p in enumerate(params):
        m[i] = beta1 * m[i] + (1 - beta1) * p.grad
        v[i] = beta2 * v[i] + (1 - beta2) * p.grad ** 2
        m_hat = m[i] / (1 - beta1 ** (step + 1))
        v_hat = v[i] / (1 - beta2 ** (step + 1))
        p.data -= lr_t * m_hat / (v_hat ** 0.5 + eps_adam)
        p.grad = 0

    print(f"step {step+1:4d} / {num_steps:4d} | loss {loss.data:.4f}")

# Inference: may the model babble back to us
temperature = 0.5 # in (0, 1], control the "creativity" of generated text, low to high
print("\\n--- inference ---")
for sample_idx in range(20):
    keys, values = [[] for _ in range(n_layer)], [[] for _ in range(n_layer)]
    token_id = BOS
    sample = []
    for pos_id in range(block_size):
        logits = gpt(token_id, pos_id, keys, values)
        probs = softmax([l / temperature for l in logits])
        token_id = random.choices(range(vocab_size), weights=[p.data for p in probs])[0]
        if token_id == BOS:
            break
        sample.append(uchars[token_id])
    print(f"sample {sample_idx+1:2d}: {''.join(sample)}")`;

        // Python syntax highlighting
        function highlightPython(code) {
            const keywords = ['def', 'class', 'return', 'if', 'else', 'elif', 'for', 'in', 'range', 'while', 'import', 'from', 'as', 'True', 'False', 'None', 'and', 'or', 'not', 'is', 'lambda', 'with', 'try', 'except', 'finally', 'raise', 'pass', 'break', 'continue', 'assert', 'global', 'nonlocal', 'del', 'yield', 'async', 'await', 'not'];
            const builtins = ['print', 'len', 'sum', 'max', 'min', 'abs', 'round', 'int', 'float', 'str', 'list', 'dict', 'set', 'tuple', 'bool', 'type', 'isinstance', 'open', 'enumerate', 'zip', 'map', 'filter', 'sorted', 'reversed', 'any', 'all', 'range'];

            // Escape HTML first
            let result = code
                .replace(/&/g, '&amp;')
                .replace(/</g, '&lt;')
                .replace(/>/g, '&gt;');

            // Mark strings and comments to prevent them from being highlighted
            const stringCommentMatches = [];
            let markerIndex = 0;

            // Match comments (must do BEFORE strings to avoid matching # inside f-strings)
            const commentRegex = /#.*$/gm;
            result = result.replace(commentRegex, (match) => {
                const idx = markerIndex++;
                stringCommentMatches[idx] = {type: 'comment', match};
                return '<<<PYHLCMT' + idx + '>>>';
            });

            // Match strings (triple, single, double quoted, including f-strings, r-strings)
            const stringRegex = /(?:[frbFRB]*"""[\s\S]*?"""|[frbFRB]*'''[\s\S]*?'''|[frbFRB]*?"(?:[^"\\]|\\.)*"|[frbFRB]*?'(?:[^'\\]|\\.)*')/g;
            result = result.replace(stringRegex, (match) => {
                const idx = markerIndex++;
                stringCommentMatches[idx] = {type: 'string', match};
                return '<<<PYHLSTR' + idx + '>>>';
            });

            // Highlight keywords (not inside strings/comments)
            const keywordPattern = new RegExp('\\b(' + keywords.join('|') + ')\\b', 'g');
            result = result.replace(keywordPattern, '<span class="py-keyword">$1</span>');

            // Highlight built-ins
            const builtinPattern = new RegExp('\\b(' + builtins.join('|') + ')\\b', 'g');
            result = result.replace(builtinPattern, '<span class="py-builtin">$1</span>');

            // Highlight function names after def/class
            result = result.replace(/\b(def|class)\s+([a-zA-Z_]\w*)/g, '<span class="py-keyword">$1</span> <span class="py-function">$2</span>');

            // Highlight numbers
            result = result.replace(/\b(\d+\.?\d*)\b/g, '<span class="py-number">$1</span>');

            // Restore comments with proper highlighting
            result = result.replace(/<<<PYHLCMT(\d+)>>>/g, (match, index) => {
                const item = stringCommentMatches[index];
                return '<span class="py-comment">' + item.match + '</span>';
            });

            // Restore strings with proper highlighting
            result = result.replace(/<<<PYHLSTR(\d+)>>>/g, (match, index) => {
                const item = stringCommentMatches[index];
                return '<span class="py-string">' + item.match + '</span>';
            });

            return result;
        }

        // Initialize code viewer
        function initCodeViewer() {
            const codeViewer = document.getElementById('codeViewer');
            const lines = pythonCode.split('\n');

            codeViewer.innerHTML = lines.map((line, index) => {
                const highlightedLine = highlightPython(line);
                return `<div class="code-line" data-line="${index + 1}">
                    <div class="code-line-number">${index + 1}</div>
                    <div class="code-line-content">${highlightedLine}</div>
                </div>`;
            }).join('');
        }

        // Highlight lines in code
        function highlightLines(lineRanges) {
            // Remove existing highlights
            document.querySelectorAll('.code-line').forEach(line => {
                line.classList.remove('highlighted');
            });

            // Parse line ranges (e.g., "10-15", "20", "5-10,20-25")
            const ranges = lineRanges.split(',').flatMap(range => {
                const [start, end] = range.trim().split('-').map(n => parseInt(n));
                if (end) {
                    return Array.from({length: end - start + 1}, (_, i) => start + i);
                }
                return [start];
            });

            // Highlight new lines
            ranges.forEach(lineNum => {
                const lineEl = document.querySelector(`.code-line[data-line="${lineNum}"]`);
                if (lineEl) {
                    lineEl.classList.add('highlighted');
                }
            });

            // Scroll to first highlighted line
            const firstLineEl = document.querySelector(`.code-line[data-line="${ranges[0]}"]`);
            if (firstLineEl) {
                firstLineEl.scrollIntoView({ behavior: 'smooth', block: 'center' });
            }
        }

        // Scroll to top
        function scrollToTop() {
            document.querySelector('.right-panel').scrollTo({ top: 0, behavior: 'smooth' });
        }

        // Tab switching
        document.querySelectorAll('.tab').forEach(tab => {
            tab.addEventListener('click', () => {
                document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
                document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));
                tab.classList.add('active');
                document.getElementById(tab.dataset.tab).classList.add('active');
            });
        });

        // Click handlers for blocks and cards
        function setupClickHandlers() {
            document.querySelectorAll('.arch-block, .param-card, .btn').forEach(el => {
                el.addEventListener('click', (e) => {
                    const lines = el.dataset.lines;
                    if (lines) {
                        highlightLines(lines);
                        e.stopPropagation();
                    }
                });
            });
        }

        // Architecture animation
        let architectureAnimationRunning = false;

        async function animateArchitecture() {
            if (architectureAnimationRunning) return;
            architectureAnimationRunning = true;

            const order = ['input', 'embed', 'prenorm', 'attn', 'residual1', 'mlp', 'residual2', 'output'];

            document.querySelectorAll('.arch-block').forEach(b => {
                b.classList.remove('active', 'pulse');
            });

            for (const blockId of order) {
                const block = document.querySelector(`.arch-block[data-block="${blockId}"]`);
                if (block) {
                    block.classList.add('active', 'pulse');
                    const lines = block.dataset.lines;
                    if (lines) {
                        highlightLines(lines);
                    }
                    await sleep(800);
                    block.classList.remove('pulse');
                }
            }

            architectureAnimationRunning = false;
        }

        // Attention grid
        function initAttentionGrid() {
            const grid = document.getElementById('attentionGrid');
            grid.innerHTML = '';

            for (let t = 0; t < 8; t++) {
                for (let tau = 0; tau < 8; tau++) {
                    const cell = document.createElement('div');
                    cell.className = 'attention-cell';
                    cell.dataset.t = t;
                    cell.dataset.tau = tau;

                    const isAttended = tau <= t;
                    const weight = isAttended ? Math.exp(-Math.abs(t - tau) * 0.5) : 0;
                    const normalized = isAttended ? weight / Array.from({length: t + 1}, (_, i) => Math.exp(-Math.abs(t - i) * 0.5)).reduce((a, b) => a + b, 0) : 0;

                    const intensity = Math.floor(normalized * 255);
                    cell.style.backgroundColor = isAttended
                        ? `rgb(${intensity}, ${intensity}, ${intensity + 50})`
                        : 'var(--bg-tertiary)';

                    cell.textContent = isAttended ? normalized.toFixed(1) : '';

                    cell.addEventListener('click', () => {
                        highlightLines('118-133');
                    });

                    grid.appendChild(cell);
                }
            }
        }

        async function animateAttention() {
            const cells = document.querySelectorAll('.attention-cell');
            cells.forEach(c => c.classList.remove('pulse'));

            for (let t = 0; t < 8; t++) {
                for (let tau = 0; tau <= t; tau++) {
                    const cell = document.querySelector(`.attention-cell[data-t="${t}"][data-tau="${tau}"]`);
                    if (cell) {
                        cell.classList.add('pulse');
                        await sleep(100);
                        cell.classList.remove('pulse');
                    }
                }
            }
        }

        function randomizeAttention() {
            const cells = document.querySelectorAll('.attention-cell');
            cells.forEach(cell => {
                const t = parseInt(cell.dataset.t);
                const tau = parseInt(cell.dataset.tau);
                const isAttended = tau <= t;

                if (isAttended) {
                    const weight = Math.random();
                    cell.style.backgroundColor = `rgb(${Math.floor(weight * 255)}, ${Math.floor(weight * 200)}, ${Math.floor(weight * 100 + 50)})`;
                    cell.textContent = weight.toFixed(1);
                }
            });
        }

        // Tooltip
        const tooltip = document.getElementById('tooltip');

        function showTooltip(e, content) {
            tooltip.innerHTML = content;
            tooltip.style.left = e.pageX + 10 + 'px';
            tooltip.style.top = e.pageY + 10 + 'px';
            tooltip.classList.add('show');
        }

        function hideTooltip() {
            tooltip.classList.remove('show');
        }

        document.addEventListener('mousemove', (e) => {
            if (tooltip.classList.contains('show')) {
                tooltip.style.left = e.pageX + 10 + 'px';
                tooltip.style.top = e.pageY + 10 + 'px';
            }
        });

        // Utility
        function sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }

        // Initialize on load
        document.addEventListener('DOMContentLoaded', () => {
            initCodeViewer();
            initAttentionGrid();
            setupClickHandlers();
        });
    </script>
</body>
</html>
